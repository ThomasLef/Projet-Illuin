{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31b2277-0e8d-4edc-9faf-b81cd989016d",
   "metadata": {},
   "source": [
    "# Scope labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fe18df-0db8-4256-8621-020529ea6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from deep_translator import GoogleTranslator\n",
    "from datetime import datetime, timedelta\n",
    "import parsedatetime as pdt\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from selenium import webdriver\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327e158e-1149-470e-86e9-ec0128fe1887",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_name = 'Wallerand' # <-- Modify here\n",
    "subject = 'Earthquake' # <-- Modify here\n",
    "year = 2021 # <-- Modify here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1a688c-d9c6-40c9-adaa-e5d2aea510af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists_from_subject(subject, num_pages,date_limits = None):\n",
    "\n",
    "    translator = GoogleTranslator(source='fr', target='en')\n",
    "    \n",
    "    cal = pdt.Calendar()\n",
    "    now = datetime.now()\n",
    "\n",
    "    PATH = \"./chromedriver.exe\"\n",
    "\n",
    "    s=Service(PATH)\n",
    "    driver = webdriver.Chrome(service=s)\n",
    "\n",
    "    link_list = []\n",
    "    date_list = []\n",
    "    if date_limits is not None:\n",
    "        lower_date, higher_date = date_limits\n",
    "        ld, lm, ly = str(lower_date.day), str(lower_date.month), str(lower_date.year)\n",
    "        hd, hm, hy = str(higher_date.day), str(higher_date.month), str(higher_date.year)\n",
    "        driver.get(\"https://www.google.com/search?q=\"+subject+\"&rlz=1C1CHBF_frFR863FR863&biw=1920&bih=880&sxsrf=APq-WBuYthkpiHNrhk_0YwH1w70zP27Xgg%3A1643812260630&source=lnt&tbs=cdr%3A1%2Ccd_min%3A\"+lm+\"%2F\"+ld+\"%2F\"+ly+\"%2Ccd_max%3A\"+hm+\"%2F\"+hd+\"%2F\"+hy+\"&tbm=nws&hl=en\")\n",
    "    else:   \n",
    "        driver.get(\"https://www.google.com/search?q=\"+subject+\"&rlz=1C1CHBF_frFR863FR863&biw=1920&bih=880&sxsrf=AOaemvI0XcPZB9YWw9GUVGwWTEXPDVqRxQ:1638967714934&source=lnms&tbm=nws&sa=X&ved=2ahUKEwjGlsnDntT0AhWTTcAKHeyuDk4Q_AUoAXoECAEQAw&hl=en\")\n",
    "\n",
    "    driver.find_element(By.XPATH, \"//button[@class='VfPpkd-LgbsSe VfPpkd-LgbsSe-OWXEXe-k8QpJ VfPpkd-LgbsSe-OWXEXe-dgl2Hf nCP5yc AjY5Oe DuMIQc qfvgSe']\").click() #accept google policy\n",
    "\n",
    "    for i in range(num_pages):\n",
    "        if i != 0:\n",
    "            try :\n",
    "                driver.find_element(By.ID, \"pnnext\").click()\n",
    "            except :\n",
    "                break\n",
    "\n",
    "        html_source = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "        #Getting all g-card \n",
    "        g_card_list = soup.find_all(\"g-card\")\n",
    "\n",
    "        for g_card in g_card_list:\n",
    "            a = g_card.find(\"a\")\n",
    "            link = a['href']\n",
    "            link_list.append(link)\n",
    "\n",
    "            date = g_card.find_all(\"span\")[-1].text\n",
    "            translated_date = translator.translate(date)\n",
    "            date_list.append(cal.parseDT(translated_date, now)[0].date())\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    print(\"Successfully scraped : \", len(link_list), \" links\")\n",
    "\n",
    "    return link_list, date_list\n",
    "\n",
    "def get_df_from_link_list(link_list, date_list):\n",
    "\n",
    "    my_timeout = 10\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i, link in enumerate(link_list):\n",
    "        d = {}\n",
    "\n",
    "        try:\n",
    "            html_text = requests.get(link, timeout=my_timeout).text\n",
    "\n",
    "            soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "            title = soup.find('title')\n",
    "            if title != None:\n",
    "                d[\"Title\"] = title.text\n",
    "\n",
    "            d[\"Link\"] = link\n",
    "   \n",
    "\n",
    "\n",
    "            d[\"Date\"] = date_list[i]\n",
    "            \n",
    "            article = soup.find('article')\n",
    "            if article != None:\n",
    "                paragraphs = article.find_all('p')\n",
    "                big_p = \"\"\n",
    "                for p in paragraphs:\n",
    "                    big_p = big_p + p.text + \" \"\n",
    "                \n",
    "                if big_p != \"\":\n",
    "                    d[\"Content\"] = unicodedata.normalize(\"NFKD\", big_p).rstrip()\n",
    "        except: #Requests takes way too long or bug\n",
    "            print('Could not scrap page number ' + str(i) + ', try again another time.')\n",
    "\n",
    "        data.append(d)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def clean(text):\n",
    "\n",
    "    \"\"\"Clean the text input\"\"\"\n",
    "    \n",
    "    # removing paragraph numbers\n",
    "    text = re.sub('[0-9]+.\\t','',str(text))\n",
    "    # removing new line characters\n",
    "    text = re.sub('\\n ','',str(text))\n",
    "    text = re.sub('\\n',' ',str(text))\n",
    "    # removing apostrophes\n",
    "    text = re.sub(\"'s\",'',str(text))\n",
    "    # removing hyphens\n",
    "    text = re.sub(\"-\",' ',str(text))\n",
    "    text = re.sub(\"â€” \",'',str(text))\n",
    "    # removing quotation marks\n",
    "    text = re.sub('\\\"','',str(text))\n",
    "    # removing salutations\n",
    "    text = re.sub(\"Mr\\.\",'Mr',str(text))\n",
    "    text = re.sub(\"Mrs\\.\",'Mrs',str(text))\n",
    "    # removing any reference to outside text\n",
    "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(text))\n",
    "\n",
    "    return text\n",
    "\n",
    "def get_df_from_subject(subject,num_pages, date_limits = None):\n",
    "    link_list, date_list = get_lists_from_subject(subject, num_pages, date_limits)\n",
    "    return get_df_from_link_list(link_list, date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "008b5ab3-cb5b-4573-a645-8300d9855b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully scraped :  10  links\n",
      "There are 6 usable articles\n"
     ]
    }
   ],
   "source": [
    "early_date = datetime(year, 1, 1) \n",
    "end_date = datetime(year, 12, 31) \n",
    "\n",
    "df = get_df_from_subject(subject,4, date_limits = (early_date, end_date))\n",
    "df = df.dropna() #Drop missing values\n",
    "df[\"Content\"] = df[\"Content\"].apply(clean) #cleaning contents\n",
    "df = df.rename(columns={\"Content\":\"Clean_content\"})\n",
    "print(f'There are {len(df.index)} usable articles')\n",
    "df['Scope'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc7ca1-ac23-4201-89ad-4d78974297df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will be asked to label articles one by one in the following cell\n",
    "# Enter 1 if the article mention specif past event linked to your sugject\n",
    "# Enter 0 otherwise (if the article only mentions predictions about the future for example)\n",
    "\n",
    "for i in range(len(df)) :\n",
    "    if df.iloc[i, -1] == None:\n",
    "        print(\"Article\", i+1, \"/\", len(df), ':')\n",
    "        text = df.iloc[i].Clean_content\n",
    "        print(text)\n",
    "        print()\n",
    "        label = input(\"In Scope ? (0 or 1)\")\n",
    "        df.iloc[i, -1] = label\n",
    "        print('############')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad62b44c-2da1-4dbf-9227-0f5daaa6d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.rename(columns = {'Clean_content' : 'text', 'Scope' : 'label'})\n",
    "df2 = df2[['text', 'label']]\n",
    "df2.to_csv('scope_dataset_'+my_name+'_'+subject+'_'+str(year)+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a157e959-548d-42b4-b225-86e0f996a656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Bureau of Meteorology says the mass of rai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UPDATE: There are a number of severe weather w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By Adam Durbin &amp; Sophie GallagherBBC News Stor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>By Christy CooneyBBC News This video can not b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Severe storms bringing heavy rainfall leading ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  The Bureau of Meteorology says the mass of rai...     0\n",
       "1  UPDATE: There are a number of severe weather w...     0\n",
       "4  By Adam Durbin & Sophie GallagherBBC News Stor...     1\n",
       "5  By Christy CooneyBBC News This video can not b...     1\n",
       "9  Severe storms bringing heavy rainfall leading ...     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10746ea0-b222-4a73-b273-3f07f4c05f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6fa46-45d9-43a4-afc4-beba9255a2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d156b-63c5-41fe-a54c-323f187c0b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47da1c48-3a8b-4f11-83c9-f35dac49a9e1",
   "metadata": {},
   "source": [
    "### (Optionnal) If you want to split your data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b95e6da-9f14-4a21-862d-a6ef0695aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.6\n",
    "x = int(len(df2)*train_test_ratio - 0.01) + 1\n",
    "train = df2.head(x)\n",
    "test = df2.tail(len(df) - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9dc2bedf-ce99-418e-8dd8-e7b0ec5d1737",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_'+my_name+'_'+subject+'.csv', index = False)\n",
    "test.to_csv('test_'+my_name+'_'+subject+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca8dc0-6e4a-430c-b944-e213a7c9f5fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
